{"ast":null,"code":"var _jsxFileName = \"/Users/oxu/react-vycxvv-proenglish/src/SpeechRecog.tsx\",\n  _s = $RefreshSig$();\nimport React, { useState, useEffect } from 'react';\nimport { replaceNumbersWithWords } from './MyLib.js';\n//import { fabClasses } from '@mui/material';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst speechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\nif (!speechRecognition) {\n  alert('Speech Recognition API is not supported in this browser');\n  //return;\n}\nconst recognition = new speechRecognition();\nrecognition.continuous = true;\nrecognition.interimResults = true;\nrecognition.lang = 'en-US';\n//recognition.lang = 'cmn-Hans-CN'; // 设置为普通话中文\n//好像没有这个方法 recognition.timeout = 30000;\n//recognition.maxAlternatives = 1; //xu\n\nconst SpeechRecog = ({\n  sendTextToParent,\n  playBackStatus,\n  isListening\n}) => {\n  _s();\n  //const [isListening, setIsListening] = useState(0);\n  const [text, setText] = useState('The spoken text will appear here after you click the button above.');\n  //console.log('enter SpeechRecog()|', \"playBackStatus=\", playBackStatus, 'isListening=', isListening);\n\n  useEffect(() => {\n    recognition.onresult = event => {\n      //console.log(event.results.map((result) => result[0]).join(\"\"));\n      //console.log('RESULTS：', event.results);\n      //console.log('最新内容：', event.results[event.results.length - 1][0]);\n      let transcript = event.results[event.results.length - 1][0].transcript;\n      transcript = replaceNumbersWithWords(transcript);\n      setText(transcript);\n      sendTextToParent(transcript);\n    };\n    recognition.onend = () => {\n      //这里绑定了一个事件。如果它与isListening无关，它应该在另一个useEffect中定义。\n      console.log('onend event: isListening=', isListening, 'playBackStatus=', playBackStatus);\n      console.log('onend event: start():, but tmply not to...');\n      //recognition.start();\n      if (isListening && !playBackStatus) {\n        console.log(\" 符合isListening&&!playBackStatus条件,start(),tmply not to...\");\n        //recognition.start();\n      } else {\n        console.log(\" 不符合isListening&&!playBackStatus条件,不执行start()\");\n      }\n    };\n    recognition.onaudioend = () => {\n      //\n      console.log('audio-end event:');\n    };\n    recognition.onerror = () => {\n      //\n      console.log('error event: isListening=', isListening, 'playBackStatus=', playBackStatus);\n    };\n    recognition.onnomatch = () => {\n      //\n      console.log('no-match event:');\n    };\n    recognition.onsoundend = () => {\n      //\n      console.log('sound-end event:');\n    };\n    recognition.onsoundstart = () => {\n      //\n      console.log('sound-start event:');\n    };\n    recognition.onspeechend = () => {\n      //\n      console.log('speech-end event:');\n    };\n    recognition.onspeechstart = () => {\n      //\n      console.log('speech-start event:');\n    };\n    recognition.onstart = () => {\n      //\n      console.log('start event:');\n    };\n  }, []);\n  let i = 0;\n  useEffect(() => {\n    //这个useEffect是为了让recognition.start()和recognition.stop()在isListening改变时执行。\n    i = i + 1;\n    console.log('enter SpeechRecog useEffect on isListening=', isListening, \"i=\", i);\n    if (isListening) {\n      console.log('execute start():');\n      recognition.start();\n    } else {\n      console.log('execute stop():');\n      recognition.stop();\n    }\n    ;\n    return () => recognition.stop();\n  }, [isListening]);\n  useEffect(() => {\n    //这个useEffect是为了让recognition.start()和recognition.stop()在playBackStatus改变时执行。\n    console.log('enter SpeechRecog useEffect on playbackstatus=', playBackStatus);\n    if (playBackStatus === true && isListening === true) {\n      console.log('playBackStatus and isListening is true, now stop listening: tmply not to...');\n      //recognition.stop();\n    }\n    if (playBackStatus === false && isListening === true) {\n      console.log('playBackStatus is false and isListening true, now start listening: tmply not to...');\n      //recognition.start();\n    }\n  }, [playBackStatus]);\n  return /*#__PURE__*/_jsxDEV(\"div\", {}, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 102,\n    columnNumber: 1\n  }, this);\n};\n_s(SpeechRecog, \"0+2zmcTTp95mQutVBaC+d9OyVcA=\");\n_c = SpeechRecog;\nexport default SpeechRecog;\nvar _c;\n$RefreshReg$(_c, \"SpeechRecog\");","map":{"version":3,"names":["React","useState","useEffect","replaceNumbersWithWords","jsxDEV","_jsxDEV","speechRecognition","window","SpeechRecognition","webkitSpeechRecognition","alert","recognition","continuous","interimResults","lang","SpeechRecog","sendTextToParent","playBackStatus","isListening","_s","text","setText","onresult","event","transcript","results","length","onend","console","log","onaudioend","onerror","onnomatch","onsoundend","onsoundstart","onspeechend","onspeechstart","onstart","i","start","stop","fileName","_jsxFileName","lineNumber","columnNumber","_c","$RefreshReg$"],"sources":["/Users/oxu/react-vycxvv-proenglish/src/SpeechRecog.tsx"],"sourcesContent":["import React, { useState, useEffect } from 'react';\nimport { replaceNumbersWithWords } from './MyLib.js';\n//import { fabClasses } from '@mui/material';\n\nconst speechRecognition =\n(window as unknown as Window & { SpeechRecognition: any }).SpeechRecognition || (window as unknown as Window & { webkitSpeechRecognition: any }).webkitSpeechRecognition;\nif (!speechRecognition) {\nalert('Speech Recognition API is not supported in this browser');\n//return;\n}\nconst recognition = new speechRecognition();\nrecognition.continuous = true;\nrecognition.interimResults = true;\nrecognition.lang = 'en-US';\n//recognition.lang = 'cmn-Hans-CN'; // 设置为普通话中文\n//好像没有这个方法 recognition.timeout = 30000;\n//recognition.maxAlternatives = 1; //xu\n\nconst SpeechRecog = ({sendTextToParent,playBackStatus,isListening}) => {\n  //const [isListening, setIsListening] = useState(0);\n  const [text, setText] = useState('The spoken text will appear here after you click the button above.');\n  //console.log('enter SpeechRecog()|', \"playBackStatus=\", playBackStatus, 'isListening=', isListening);\n\n  useEffect(() => {\n\n    recognition.onresult = (event) => {\n      //console.log(event.results.map((result) => result[0]).join(\"\"));\n      //console.log('RESULTS：', event.results);\n      //console.log('最新内容：', event.results[event.results.length - 1][0]);\n      let transcript = event.results[event.results.length - 1][0].transcript;\n      transcript = replaceNumbersWithWords(transcript);\n      setText(transcript);\n      sendTextToParent(transcript);\n    };\n\n    recognition.onend = () => { //这里绑定了一个事件。如果它与isListening无关，它应该在另一个useEffect中定义。\n      console.log('onend event: isListening=', isListening, 'playBackStatus=', playBackStatus);\n      console.log('onend event: start():, but tmply not to...');\n      //recognition.start();\n      if (isListening && !playBackStatus) {\n        console.log(\" 符合isListening&&!playBackStatus条件,start(),tmply not to...\");\n        //recognition.start();\n      }else{\n        console.log(\" 不符合isListening&&!playBackStatus条件,不执行start()\");\n      }\n    };\n\n    recognition.onaudioend = () => { //\n      console.log('audio-end event:');\n    };\n    recognition.onerror = () => { //\n      console.log('error event: isListening=', isListening, 'playBackStatus=', playBackStatus);\n    };\n    recognition.onnomatch = () => { //\n      console.log('no-match event:');\n    };\n\n    recognition.onsoundend = () => { //\n      console.log('sound-end event:');\n    };\n    recognition.onsoundstart = () => { //\n      console.log('sound-start event:');\n    };\n    recognition.onspeechend = () => { //\n      console.log('speech-end event:');\n    };\n    recognition.onspeechstart = () => { //\n      console.log('speech-start event:');\n    };\n    recognition.onstart = () => { //\n      console.log('start event:');\n    };\n  }, []);\n\n  let i = 0;\n  useEffect(() => { //这个useEffect是为了让recognition.start()和recognition.stop()在isListening改变时执行。\n    i = i + 1;\n    console.log('enter SpeechRecog useEffect on isListening=', isListening, \"i=\",i);\n    if (isListening) {\n      console.log('execute start():');\n      recognition.start();\n    }else{\n      console.log('execute stop():');\n      recognition.stop()\n    };\n    return () => recognition.stop();\n  }, [isListening]);\n\n  useEffect(() => { //这个useEffect是为了让recognition.start()和recognition.stop()在playBackStatus改变时执行。\n    console.log('enter SpeechRecog useEffect on playbackstatus=', playBackStatus);\n    if (playBackStatus === true && isListening === true) {\n      console.log('playBackStatus and isListening is true, now stop listening: tmply not to...');\n      //recognition.stop();\n    }\n    if (playBackStatus === false && isListening === true) {\n      console.log('playBackStatus is false and isListening true, now start listening: tmply not to...');\n      //recognition.start();\n    }\n  },[playBackStatus]);\n\n  return (\n<div></div>\n  );\n};\n\nexport default SpeechRecog;\n"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,QAAQ,EAAEC,SAAS,QAAQ,OAAO;AAClD,SAASC,uBAAuB,QAAQ,YAAY;AACpD;AAAA,SAAAC,MAAA,IAAAC,OAAA;AAEA,MAAMC,iBAAiB,GACtBC,MAAM,CAAoDC,iBAAiB,IAAKD,MAAM,CAA0DE,uBAAuB;AACxK,IAAI,CAACH,iBAAiB,EAAE;EACxBI,KAAK,CAAC,yDAAyD,CAAC;EAChE;AACA;AACA,MAAMC,WAAW,GAAG,IAAIL,iBAAiB,CAAC,CAAC;AAC3CK,WAAW,CAACC,UAAU,GAAG,IAAI;AAC7BD,WAAW,CAACE,cAAc,GAAG,IAAI;AACjCF,WAAW,CAACG,IAAI,GAAG,OAAO;AAC1B;AACA;AACA;;AAEA,MAAMC,WAAW,GAAGA,CAAC;EAACC,gBAAgB;EAACC,cAAc;EAACC;AAAW,CAAC,KAAK;EAAAC,EAAA;EACrE;EACA,MAAM,CAACC,IAAI,EAAEC,OAAO,CAAC,GAAGpB,QAAQ,CAAC,oEAAoE,CAAC;EACtG;;EAEAC,SAAS,CAAC,MAAM;IAEdS,WAAW,CAACW,QAAQ,GAAIC,KAAK,IAAK;MAChC;MACA;MACA;MACA,IAAIC,UAAU,GAAGD,KAAK,CAACE,OAAO,CAACF,KAAK,CAACE,OAAO,CAACC,MAAM,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAACF,UAAU;MACtEA,UAAU,GAAGrB,uBAAuB,CAACqB,UAAU,CAAC;MAChDH,OAAO,CAACG,UAAU,CAAC;MACnBR,gBAAgB,CAACQ,UAAU,CAAC;IAC9B,CAAC;IAEDb,WAAW,CAACgB,KAAK,GAAG,MAAM;MAAE;MAC1BC,OAAO,CAACC,GAAG,CAAC,2BAA2B,EAAEX,WAAW,EAAE,iBAAiB,EAAED,cAAc,CAAC;MACxFW,OAAO,CAACC,GAAG,CAAC,4CAA4C,CAAC;MACzD;MACA,IAAIX,WAAW,IAAI,CAACD,cAAc,EAAE;QAClCW,OAAO,CAACC,GAAG,CAAC,2DAA2D,CAAC;QACxE;MACF,CAAC,MAAI;QACHD,OAAO,CAACC,GAAG,CAAC,+CAA+C,CAAC;MAC9D;IACF,CAAC;IAEDlB,WAAW,CAACmB,UAAU,GAAG,MAAM;MAAE;MAC/BF,OAAO,CAACC,GAAG,CAAC,kBAAkB,CAAC;IACjC,CAAC;IACDlB,WAAW,CAACoB,OAAO,GAAG,MAAM;MAAE;MAC5BH,OAAO,CAACC,GAAG,CAAC,2BAA2B,EAAEX,WAAW,EAAE,iBAAiB,EAAED,cAAc,CAAC;IAC1F,CAAC;IACDN,WAAW,CAACqB,SAAS,GAAG,MAAM;MAAE;MAC9BJ,OAAO,CAACC,GAAG,CAAC,iBAAiB,CAAC;IAChC,CAAC;IAEDlB,WAAW,CAACsB,UAAU,GAAG,MAAM;MAAE;MAC/BL,OAAO,CAACC,GAAG,CAAC,kBAAkB,CAAC;IACjC,CAAC;IACDlB,WAAW,CAACuB,YAAY,GAAG,MAAM;MAAE;MACjCN,OAAO,CAACC,GAAG,CAAC,oBAAoB,CAAC;IACnC,CAAC;IACDlB,WAAW,CAACwB,WAAW,GAAG,MAAM;MAAE;MAChCP,OAAO,CAACC,GAAG,CAAC,mBAAmB,CAAC;IAClC,CAAC;IACDlB,WAAW,CAACyB,aAAa,GAAG,MAAM;MAAE;MAClCR,OAAO,CAACC,GAAG,CAAC,qBAAqB,CAAC;IACpC,CAAC;IACDlB,WAAW,CAAC0B,OAAO,GAAG,MAAM;MAAE;MAC5BT,OAAO,CAACC,GAAG,CAAC,cAAc,CAAC;IAC7B,CAAC;EACH,CAAC,EAAE,EAAE,CAAC;EAEN,IAAIS,CAAC,GAAG,CAAC;EACTpC,SAAS,CAAC,MAAM;IAAE;IAChBoC,CAAC,GAAGA,CAAC,GAAG,CAAC;IACTV,OAAO,CAACC,GAAG,CAAC,6CAA6C,EAAEX,WAAW,EAAE,IAAI,EAACoB,CAAC,CAAC;IAC/E,IAAIpB,WAAW,EAAE;MACfU,OAAO,CAACC,GAAG,CAAC,kBAAkB,CAAC;MAC/BlB,WAAW,CAAC4B,KAAK,CAAC,CAAC;IACrB,CAAC,MAAI;MACHX,OAAO,CAACC,GAAG,CAAC,iBAAiB,CAAC;MAC9BlB,WAAW,CAAC6B,IAAI,CAAC,CAAC;IACpB;IAAC;IACD,OAAO,MAAM7B,WAAW,CAAC6B,IAAI,CAAC,CAAC;EACjC,CAAC,EAAE,CAACtB,WAAW,CAAC,CAAC;EAEjBhB,SAAS,CAAC,MAAM;IAAE;IAChB0B,OAAO,CAACC,GAAG,CAAC,gDAAgD,EAAEZ,cAAc,CAAC;IAC7E,IAAIA,cAAc,KAAK,IAAI,IAAIC,WAAW,KAAK,IAAI,EAAE;MACnDU,OAAO,CAACC,GAAG,CAAC,6EAA6E,CAAC;MAC1F;IACF;IACA,IAAIZ,cAAc,KAAK,KAAK,IAAIC,WAAW,KAAK,IAAI,EAAE;MACpDU,OAAO,CAACC,GAAG,CAAC,oFAAoF,CAAC;MACjG;IACF;EACF,CAAC,EAAC,CAACZ,cAAc,CAAC,CAAC;EAEnB,oBACFZ,OAAA;IAAAoC,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OAAU,CAAC;AAEX,CAAC;AAACzB,EAAA,CArFIJ,WAAW;AAAA8B,EAAA,GAAX9B,WAAW;AAuFjB,eAAeA,WAAW;AAAC,IAAA8B,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}