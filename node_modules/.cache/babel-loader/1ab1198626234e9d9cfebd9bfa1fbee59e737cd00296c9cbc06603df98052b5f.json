{"ast":null,"code":"var _jsxFileName = \"/Users/oxu/react-vycxvv-proenglish/src/SpeechToText.tsx\",\n  _s = $RefreshSig$();\nimport React, { useState, useEffect } from 'react';\nimport { replaceNumbersWithWords } from './MyLib.js';\n//import { fabClasses } from '@mui/material';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst speechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\nif (!speechRecognition) {\n  alert('Speech Recognition API is not supported in this browser');\n  //return;\n}\nconst recognition = new speechRecognition();\nrecognition.continuous = true;\nrecognition.interimResults = true;\nrecognition.lang = 'en-US';\n//recognition.lang = 'cmn-Hans-CN'; // 设置为普通话中文\n\n//好像没有这个方法 recognition.timeout = 30000;\n//recognition.maxAlternatives = 1; //xu\n\nconst SpeechToText = ({\n  sendTextToParent,\n  playBackStatus\n}) => {\n  _s();\n  const [isListening, setIsListening] = useState(false);\n  const [text, setText] = useState('The spoken text will appear here after you click the button above.');\n  //console.log('enter SpeechToText()...');\n  //console.log('SpeechToText | playBackStatus=', playBackStatus);\n  recognition.onresult = event => {\n    //console.log(event.results.map((result) => result[0]).join(\"\"));\n    //console.log('RESULTS：', event.results);\n    //console.log('最新内容：', event.results[event.results.length - 1][0]);\n    let transcript = event.results[event.results.length - 1][0].transcript;\n    transcript = replaceNumbersWithWords(transcript);\n    setText(transcript);\n    sendTextToParent(transcript);\n  };\n  useEffect(() => {\n    recognition.onend = () => {\n      //这里绑定了一个事件。如果它与isListening无关，它应该在另一个useEffect中定义。\n      console.log('onend event,should start again but tmply not to...');\n      //if (isListening && !playBackStatus) {\n      //console.log(\"in onend event | recognition.start()...\");\n      //recognition.start();\n      //}\n    };\n    recognition.onaudioend = () => {\n      //\n      console.log('audion end event:');\n    };\n    recognition.onerror = () => {\n      //\n      console.log('error event:');\n    };\n    recognition.onnomatch = () => {\n      //\n      console.log('no match event:');\n    };\n    recognition.onresult = () => {\n      //\n      console.log('result event:');\n    };\n    recognition.onsoundend = () => {\n      //\n      console.log('sound end event:');\n    };\n    recognition.onsoundstart = () => {\n      //\n      console.log('sound start event:');\n    };\n    recognition.onspeechend = () => {\n      //\n      console.log('speech end event:');\n    };\n    recognition.onspeechstart = () => {\n      //\n      console.log('onspeechstart event:');\n    };\n    recognition.onstart = () => {\n      //\n      console.log('start event:');\n    };\n  }, []);\n  let i = 0;\n  useEffect(() => {\n    //这个useEffect是为了让recognition.start()和recognition.stop()在isListening改变时执行。\n    i = i + 1;\n    console.log('into useEffect.i=', i);\n    if (isListening) {\n      console.log('execute recognition.start():');\n      recognition.start();\n    } else {\n      console.log('execute recognition.stop():');\n      recognition.stop();\n    }\n    ;\n\n    //return () => recognition.stop();\n  }, [isListening]);\n  useEffect(() => {\n    //这个useEffect是为了让recognition.start()和recognition.stop()在playBackStatus改变时执行。\n    //console.log('in SpeechToText useEffect - playbackstatus=', playBackStatus);\n    if (playBackStatus === true && isListening === true) {\n      console.log('playBackStatus is true, so stop listening...');\n      recognition.stop();\n    }\n    if (playBackStatus === false && isListening === true) {\n      //recognition.start();\n    }\n  }, [playBackStatus]);\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    children: [/*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 109,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      style: {\n        display: 'flex',\n        justifyContent: 'center'\n      },\n      children: /*#__PURE__*/_jsxDEV(\"button\", {\n        style: {\n          height: 30,\n          backgroundColor: 'green',\n          color: 'white',\n          padding: '5px',\n          borderRadius: '5px',\n          fontWeight: 'bold',\n          boxShadow: '0 2px 5px rgba(0,0,0,0.2)',\n          transition: '0.3s',\n          border: '1px solid r'\n        },\n        color: \"primary\",\n        onClick: () => setIsListening(prevIsListening => !prevIsListening),\n        children: [/*#__PURE__*/_jsxDEV(\"i\", {\n          className: \"fas fa-microphone\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 122,\n          columnNumber: 9\n        }, this), isListening ? ' STOP' : ' START']\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 112,\n        columnNumber: 9\n      }, this)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 110,\n      columnNumber: 7\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 108,\n    columnNumber: 5\n  }, this);\n};\n_s(SpeechToText, \"BM6P8zdxXZ2MThF0yMRDChh2wGY=\");\n_c = SpeechToText;\nexport default SpeechToText;\nvar _c;\n$RefreshReg$(_c, \"SpeechToText\");","map":{"version":3,"names":["React","useState","useEffect","replaceNumbersWithWords","jsxDEV","_jsxDEV","speechRecognition","window","SpeechRecognition","webkitSpeechRecognition","alert","recognition","continuous","interimResults","lang","SpeechToText","sendTextToParent","playBackStatus","_s","isListening","setIsListening","text","setText","onresult","event","transcript","results","length","onend","console","log","onaudioend","onerror","onnomatch","onsoundend","onsoundstart","onspeechend","onspeechstart","onstart","i","start","stop","children","fileName","_jsxFileName","lineNumber","columnNumber","style","display","justifyContent","height","backgroundColor","color","padding","borderRadius","fontWeight","boxShadow","transition","border","onClick","prevIsListening","className","_c","$RefreshReg$"],"sources":["/Users/oxu/react-vycxvv-proenglish/src/SpeechToText.tsx"],"sourcesContent":["import React, { useState, useEffect } from 'react';\nimport { replaceNumbersWithWords } from './MyLib.js';\n//import { fabClasses } from '@mui/material';\n\n\nconst speechRecognition =\n  (window as unknown as Window & { SpeechRecognition: any }).SpeechRecognition || (window as unknown as Window & { webkitSpeechRecognition: any }).webkitSpeechRecognition;\nif (!speechRecognition) {\n  alert('Speech Recognition API is not supported in this browser');\n  //return;\n}\n\nconst recognition = new speechRecognition();\nrecognition.continuous = true;\nrecognition.interimResults = true;\nrecognition.lang = 'en-US';\n//recognition.lang = 'cmn-Hans-CN'; // 设置为普通话中文\n\n//好像没有这个方法 recognition.timeout = 30000;\n//recognition.maxAlternatives = 1; //xu\n\nconst SpeechToText = ({sendTextToParent,playBackStatus}) => {\n  const [isListening, setIsListening] = useState(false);\n  const [text, setText] = useState('The spoken text will appear here after you click the button above.');\n  //console.log('enter SpeechToText()...');\n  //console.log('SpeechToText | playBackStatus=', playBackStatus);\n  recognition.onresult = (event) => {\n    //console.log(event.results.map((result) => result[0]).join(\"\"));\n    //console.log('RESULTS：', event.results);\n    //console.log('最新内容：', event.results[event.results.length - 1][0]);\n    let transcript = event.results[event.results.length - 1][0].transcript;\n    transcript = replaceNumbersWithWords(transcript);\n    setText(transcript);\n    sendTextToParent(transcript);\n  };\n\nuseEffect(() => {\n  recognition.onend = () => { //这里绑定了一个事件。如果它与isListening无关，它应该在另一个useEffect中定义。\n    console.log('onend event,should start again but tmply not to...');\n    //if (isListening && !playBackStatus) {\n      //console.log(\"in onend event | recognition.start()...\");\n    //recognition.start();\n    //}\n  };\n\n  recognition.onaudioend = () => { //\n    console.log('audion end event:');\n  };\n  recognition.onerror = () => { //\n    console.log('error event:');\n  };\n  recognition.onnomatch = () => { //\n    console.log('no match event:');\n  };\n  recognition.onresult = () => { //\n    console.log('result event:');\n  };\n  recognition.onsoundend = () => { //\n    console.log('sound end event:');\n  };\n  recognition.onsoundstart = () => { //\n    console.log('sound start event:');\n  };\n  recognition.onspeechend = () => { //\n    console.log('speech end event:');\n  };\n  recognition.onspeechstart = () => { //\n    console.log('onspeechstart event:');\n  };\n  recognition.onstart = () => { //\n    console.log('start event:');\n  };\n\n\n\n}, []);\n\n  let i = 0;\n  useEffect(() => { //这个useEffect是为了让recognition.start()和recognition.stop()在isListening改变时执行。\n    i = i + 1;\n    console.log('into useEffect.i=', i);\n\n\n    if (isListening) {\n      console.log('execute recognition.start():');\n      recognition.start();\n    }else{\n      console.log('execute recognition.stop():');\n      recognition.stop()\n    };\n\n\n    //return () => recognition.stop();\n  }, [isListening]);\n\n  useEffect(() => { //这个useEffect是为了让recognition.start()和recognition.stop()在playBackStatus改变时执行。\n    //console.log('in SpeechToText useEffect - playbackstatus=', playBackStatus);\n    if (playBackStatus === true && isListening === true) {\n      console.log('playBackStatus is true, so stop listening...');\n      recognition.stop();\n    }\n    if (playBackStatus === false && isListening === true) {\n      //recognition.start();\n    }\n  },[playBackStatus]);\n\n  return (\n    <div>\n      <br />\n      <div style={{display:'flex', justifyContent:'center'}}> \n        \n        <button style={{height:30,\n          backgroundColor:'green', \n          color:'white',padding:'5px', \n          borderRadius:'5px', \n          fontWeight:'bold',  \n          boxShadow:'0 2px 5px rgba(0,0,0,0.2)', \n          transition:'0.3s', \n          border:'1px solid r'}} \n          color=\"primary\" \n          onClick={() => setIsListening((prevIsListening) => !prevIsListening)}>\n        <i className=\"fas fa-microphone\"></i>\n        {isListening ? ' STOP' : ' START'}\n        </button>\n      </div>\n    </div>\n  );\n};\n\nexport default SpeechToText;\n"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,QAAQ,EAAEC,SAAS,QAAQ,OAAO;AAClD,SAASC,uBAAuB,QAAQ,YAAY;AACpD;AAAA,SAAAC,MAAA,IAAAC,OAAA;AAGA,MAAMC,iBAAiB,GACpBC,MAAM,CAAoDC,iBAAiB,IAAKD,MAAM,CAA0DE,uBAAuB;AAC1K,IAAI,CAACH,iBAAiB,EAAE;EACtBI,KAAK,CAAC,yDAAyD,CAAC;EAChE;AACF;AAEA,MAAMC,WAAW,GAAG,IAAIL,iBAAiB,CAAC,CAAC;AAC3CK,WAAW,CAACC,UAAU,GAAG,IAAI;AAC7BD,WAAW,CAACE,cAAc,GAAG,IAAI;AACjCF,WAAW,CAACG,IAAI,GAAG,OAAO;AAC1B;;AAEA;AACA;;AAEA,MAAMC,YAAY,GAAGA,CAAC;EAACC,gBAAgB;EAACC;AAAc,CAAC,KAAK;EAAAC,EAAA;EAC1D,MAAM,CAACC,WAAW,EAAEC,cAAc,CAAC,GAAGnB,QAAQ,CAAC,KAAK,CAAC;EACrD,MAAM,CAACoB,IAAI,EAAEC,OAAO,CAAC,GAAGrB,QAAQ,CAAC,oEAAoE,CAAC;EACtG;EACA;EACAU,WAAW,CAACY,QAAQ,GAAIC,KAAK,IAAK;IAChC;IACA;IACA;IACA,IAAIC,UAAU,GAAGD,KAAK,CAACE,OAAO,CAACF,KAAK,CAACE,OAAO,CAACC,MAAM,GAAG,CAAC,CAAC,CAAC,CAAC,CAAC,CAACF,UAAU;IACtEA,UAAU,GAAGtB,uBAAuB,CAACsB,UAAU,CAAC;IAChDH,OAAO,CAACG,UAAU,CAAC;IACnBT,gBAAgB,CAACS,UAAU,CAAC;EAC9B,CAAC;EAEHvB,SAAS,CAAC,MAAM;IACdS,WAAW,CAACiB,KAAK,GAAG,MAAM;MAAE;MAC1BC,OAAO,CAACC,GAAG,CAAC,oDAAoD,CAAC;MACjE;MACE;MACF;MACA;IACF,CAAC;IAEDnB,WAAW,CAACoB,UAAU,GAAG,MAAM;MAAE;MAC/BF,OAAO,CAACC,GAAG,CAAC,mBAAmB,CAAC;IAClC,CAAC;IACDnB,WAAW,CAACqB,OAAO,GAAG,MAAM;MAAE;MAC5BH,OAAO,CAACC,GAAG,CAAC,cAAc,CAAC;IAC7B,CAAC;IACDnB,WAAW,CAACsB,SAAS,GAAG,MAAM;MAAE;MAC9BJ,OAAO,CAACC,GAAG,CAAC,iBAAiB,CAAC;IAChC,CAAC;IACDnB,WAAW,CAACY,QAAQ,GAAG,MAAM;MAAE;MAC7BM,OAAO,CAACC,GAAG,CAAC,eAAe,CAAC;IAC9B,CAAC;IACDnB,WAAW,CAACuB,UAAU,GAAG,MAAM;MAAE;MAC/BL,OAAO,CAACC,GAAG,CAAC,kBAAkB,CAAC;IACjC,CAAC;IACDnB,WAAW,CAACwB,YAAY,GAAG,MAAM;MAAE;MACjCN,OAAO,CAACC,GAAG,CAAC,oBAAoB,CAAC;IACnC,CAAC;IACDnB,WAAW,CAACyB,WAAW,GAAG,MAAM;MAAE;MAChCP,OAAO,CAACC,GAAG,CAAC,mBAAmB,CAAC;IAClC,CAAC;IACDnB,WAAW,CAAC0B,aAAa,GAAG,MAAM;MAAE;MAClCR,OAAO,CAACC,GAAG,CAAC,sBAAsB,CAAC;IACrC,CAAC;IACDnB,WAAW,CAAC2B,OAAO,GAAG,MAAM;MAAE;MAC5BT,OAAO,CAACC,GAAG,CAAC,cAAc,CAAC;IAC7B,CAAC;EAIH,CAAC,EAAE,EAAE,CAAC;EAEJ,IAAIS,CAAC,GAAG,CAAC;EACTrC,SAAS,CAAC,MAAM;IAAE;IAChBqC,CAAC,GAAGA,CAAC,GAAG,CAAC;IACTV,OAAO,CAACC,GAAG,CAAC,mBAAmB,EAAES,CAAC,CAAC;IAGnC,IAAIpB,WAAW,EAAE;MACfU,OAAO,CAACC,GAAG,CAAC,8BAA8B,CAAC;MAC3CnB,WAAW,CAAC6B,KAAK,CAAC,CAAC;IACrB,CAAC,MAAI;MACHX,OAAO,CAACC,GAAG,CAAC,6BAA6B,CAAC;MAC1CnB,WAAW,CAAC8B,IAAI,CAAC,CAAC;IACpB;IAAC;;IAGD;EACF,CAAC,EAAE,CAACtB,WAAW,CAAC,CAAC;EAEjBjB,SAAS,CAAC,MAAM;IAAE;IAChB;IACA,IAAIe,cAAc,KAAK,IAAI,IAAIE,WAAW,KAAK,IAAI,EAAE;MACnDU,OAAO,CAACC,GAAG,CAAC,8CAA8C,CAAC;MAC3DnB,WAAW,CAAC8B,IAAI,CAAC,CAAC;IACpB;IACA,IAAIxB,cAAc,KAAK,KAAK,IAAIE,WAAW,KAAK,IAAI,EAAE;MACpD;IAAA;EAEJ,CAAC,EAAC,CAACF,cAAc,CAAC,CAAC;EAEnB,oBACEZ,OAAA;IAAAqC,QAAA,gBACErC,OAAA;MAAAsC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAK,CAAC,eACNzC,OAAA;MAAK0C,KAAK,EAAE;QAACC,OAAO,EAAC,MAAM;QAAEC,cAAc,EAAC;MAAQ,CAAE;MAAAP,QAAA,eAEpDrC,OAAA;QAAQ0C,KAAK,EAAE;UAACG,MAAM,EAAC,EAAE;UACvBC,eAAe,EAAC,OAAO;UACvBC,KAAK,EAAC,OAAO;UAACC,OAAO,EAAC,KAAK;UAC3BC,YAAY,EAAC,KAAK;UAClBC,UAAU,EAAC,MAAM;UACjBC,SAAS,EAAC,2BAA2B;UACrCC,UAAU,EAAC,MAAM;UACjBC,MAAM,EAAC;QAAa,CAAE;QACtBN,KAAK,EAAC,SAAS;QACfO,OAAO,EAAEA,CAAA,KAAMvC,cAAc,CAAEwC,eAAe,IAAK,CAACA,eAAe,CAAE;QAAAlB,QAAA,gBACvErC,OAAA;UAAGwD,SAAS,EAAC;QAAmB;UAAAlB,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAI,CAAC,EACpC3B,WAAW,GAAG,OAAO,GAAG,QAAQ;MAAA;QAAAwB,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OACzB;IAAC;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACN,CAAC;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACH,CAAC;AAEV,CAAC;AAAC5B,EAAA,CA1GIH,YAAY;AAAA+C,EAAA,GAAZ/C,YAAY;AA4GlB,eAAeA,YAAY;AAAC,IAAA+C,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}